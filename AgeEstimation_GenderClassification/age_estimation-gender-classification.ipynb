{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training a CNN for Estimating Person Age and Predicting its Gender from its Image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. Import the Relevent Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np, cv2, pandas as pd, glob, time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models, datasets\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Fetch the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/a/39225039/4126114\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    def get_confirm_token(response):\n",
    "        for key, value in response.cookies.items():\n",
    "            if key.startswith('download_warning'):\n",
    "                return value\n",
    "\n",
    "        return None\n",
    "\n",
    "    def save_response_content(response, destination):\n",
    "        CHUNK_SIZE = 32768\n",
    "\n",
    "        with open(destination, \"wb\") as f:\n",
    "            for chunk in response.iter_content(CHUNK_SIZE):\n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_file_from_google_drive('1k5vvyREmHDW5TSM9QgB04Bvc8C8_7dl-','fairface-label-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_file_from_google_drive('1_rtz1M1zhvS0d5vVoXUamnohB6cJ02iJ','fairface-label-val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download_file_from_google_drive('1Z1RqRo0_JiavaZw2yzZG6WETdZQ8qX86','fairface-img-margin025-trainval.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip fairface-img-margin025-trainval.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('fairface-label-train.csv')\n",
    "validation_df = pd.read_csv('fairface-label-val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1.jpg</td>\n",
       "      <td>59</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/2.jpg</td>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/4.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/5.jpg</td>\n",
       "      <td>26</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file  age  gender        race  service_test\n",
       "0  train/1.jpg   59    Male  East Asian          True\n",
       "1  train/2.jpg   39  Female      Indian         False\n",
       "2  train/3.jpg   11  Female       Black         False\n",
       "3  train/4.jpg   26  Female      Indian          True\n",
       "4  train/5.jpg   26  Female      Indian          True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val/1.jpg</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val/2.jpg</td>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/3.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val/4.jpg</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>Latino_Hispanic</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/5.jpg</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  age  gender             race  service_test\n",
       "0  val/1.jpg   11    Male       East Asian         False\n",
       "1  val/2.jpg   51  Female       East Asian          True\n",
       "2  val/3.jpg   37    Male            White          True\n",
       "3  val/4.jpg   25  Female  Latino_Hispanic          True\n",
       "4  val/5.jpg   24    Male  Southeast Asian         False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Preparing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderAge(Dataset):\n",
    "    def __init__(self,df,tfms=None):\n",
    "        self.df = df\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, indx):\n",
    "        person = self.df.iloc[indx].squeeze()\n",
    "        image_path = person.file\n",
    "        gender = person.gender == 'Female'\n",
    "        age = person.age\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        return image, age , gender\n",
    "    \n",
    "    def preprocess_image(self,image):\n",
    "        image = cv2.resize(image, (224,224))\n",
    "        image = torch.tensor(image).permute(2,0,1)\n",
    "        image = self.normalize(image/255.)\n",
    "        \n",
    "        return image[None]\n",
    "    \n",
    "    def collate_fn(self,batch):\n",
    "        images, ages, genders = [],[],[]\n",
    "        for image, age, gender in batch:\n",
    "            image = self.preprocess_image(image)\n",
    "            images.append(image)\n",
    "            ages.append(float(int(80)/80))\n",
    "            genders.append(float(gender))\n",
    "            \n",
    "        ages, genders = [torch.tensor(x).to(device).float() for x in [ages, genders]]\n",
    "        images = torch.cat(images).to(device)\n",
    "        \n",
    "        \n",
    "        return images, ages, genders   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GenderAge(train_df)\n",
    "validation_dataset = GenderAge(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_loader = DataLoader(train_dataset,\n",
    "                                  batch_size=32,\n",
    "                                  shuffle=True,\n",
    "                                  drop_last=True,\n",
    "                                  collate_fn=train_dataset.collate_fn\n",
    "                                 )\n",
    "validation_dataset_loader = DataLoader(validation_dataset, \n",
    "                                      batch_size=32, \n",
    "                                      shuffle=True, \n",
    "                                      drop_last=True,\n",
    "                                      collate_fn=validation_dataset.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_batch,ages_batch,genders_batch = next(iter(train_dataset_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 224, 224])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    vgg_16 = models.vgg16(pretrained = True)\n",
    "    for parameter in vgg_16.parameters():\n",
    "        parameter.requires_grad = False\n",
    "    \n",
    "    vgg_16.avgpool = nn.Sequential(\n",
    "        nn.Conv2d(512,512, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten())\n",
    "   \n",
    "    class AgeGenderClassifier(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(AgeGenderClassifier, self).__init__()\n",
    "            self.intermediate = nn.Sequential(\n",
    "                                                nn.Linear(2048,512),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Dropout(0.4),\n",
    "                                                nn.Linear(512,128),\n",
    "                                                nn.ReLU(),\n",
    "                                                nn.Dropout(0.4),\n",
    "                                                nn.Linear(128,64),\n",
    "                                                nn.ReLU()\n",
    "                                              )\n",
    "            self.age_classifier = nn.Sequential(\n",
    "                                                nn.Linear(64, 1),\n",
    "                                                nn.Sigmoid()\n",
    "                                                )\n",
    "            self.gender_classifier = nn.Sequential(\n",
    "                                                nn.Linear(64, 1),\n",
    "                                                nn.Sigmoid()\n",
    "                                                )\n",
    "        def forward(self, x):\n",
    "            x = self.intermediate(x)\n",
    "            age = self.age_classifier(x)\n",
    "            gender = self.gender_classifier(x)\n",
    "            return gender, age\n",
    "    \n",
    "    vgg_16.classifier = AgeGenderClassifier()\n",
    "    \n",
    "    gender_loss_function = nn.BCELoss()\n",
    "    age_loss_function = nn.L1Loss()\n",
    "    loss_functions = gender_loss_function, age_loss_function\n",
    "    optimizer = torch.optim.Adam(vgg_16.parameters(), lr = 1e-4)\n",
    "    \n",
    "    return vgg_16.to(device), loss_functions, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_functions, optimizer = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "├─Sequential: 1-1                        --\n",
      "|    └─Conv2d: 2-1                       (1,792)\n",
      "|    └─ReLU: 2-2                         --\n",
      "|    └─Conv2d: 2-3                       (36,928)\n",
      "|    └─ReLU: 2-4                         --\n",
      "|    └─MaxPool2d: 2-5                    --\n",
      "|    └─Conv2d: 2-6                       (73,856)\n",
      "|    └─ReLU: 2-7                         --\n",
      "|    └─Conv2d: 2-8                       (147,584)\n",
      "|    └─ReLU: 2-9                         --\n",
      "|    └─MaxPool2d: 2-10                   --\n",
      "|    └─Conv2d: 2-11                      (295,168)\n",
      "|    └─ReLU: 2-12                        --\n",
      "|    └─Conv2d: 2-13                      (590,080)\n",
      "|    └─ReLU: 2-14                        --\n",
      "|    └─Conv2d: 2-15                      (590,080)\n",
      "|    └─ReLU: 2-16                        --\n",
      "|    └─MaxPool2d: 2-17                   --\n",
      "|    └─Conv2d: 2-18                      (1,180,160)\n",
      "|    └─ReLU: 2-19                        --\n",
      "|    └─Conv2d: 2-20                      (2,359,808)\n",
      "|    └─ReLU: 2-21                        --\n",
      "|    └─Conv2d: 2-22                      (2,359,808)\n",
      "|    └─ReLU: 2-23                        --\n",
      "|    └─MaxPool2d: 2-24                   --\n",
      "|    └─Conv2d: 2-25                      (2,359,808)\n",
      "|    └─ReLU: 2-26                        --\n",
      "|    └─Conv2d: 2-27                      (2,359,808)\n",
      "|    └─ReLU: 2-28                        --\n",
      "|    └─Conv2d: 2-29                      (2,359,808)\n",
      "|    └─ReLU: 2-30                        --\n",
      "|    └─MaxPool2d: 2-31                   --\n",
      "├─Sequential: 1-2                        --\n",
      "|    └─Conv2d: 2-32                      2,359,808\n",
      "|    └─MaxPool2d: 2-33                   --\n",
      "|    └─ReLU: 2-34                        --\n",
      "|    └─Flatten: 2-35                     --\n",
      "├─AgeGenderClassifier: 1-3               --\n",
      "|    └─Sequential: 2-36                  --\n",
      "|    |    └─Linear: 3-1                  1,049,088\n",
      "|    |    └─ReLU: 3-2                    --\n",
      "|    |    └─Dropout: 3-3                 --\n",
      "|    |    └─Linear: 3-4                  65,664\n",
      "|    |    └─ReLU: 3-5                    --\n",
      "|    |    └─Dropout: 3-6                 --\n",
      "|    |    └─Linear: 3-7                  8,256\n",
      "|    |    └─ReLU: 3-8                    --\n",
      "|    └─Sequential: 2-37                  --\n",
      "|    |    └─Linear: 3-9                  65\n",
      "|    |    └─Sigmoid: 3-10                --\n",
      "|    └─Sequential: 2-38                  --\n",
      "|    |    └─Linear: 3-11                 65\n",
      "|    |    └─Sigmoid: 3-12                --\n",
      "=================================================================\n",
      "Total params: 18,197,634\n",
      "Trainable params: 3,482,946\n",
      "Non-trainable params: 14,714,688\n",
      "=================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "├─Sequential: 1-1                        --\n",
       "|    └─Conv2d: 2-1                       (1,792)\n",
       "|    └─ReLU: 2-2                         --\n",
       "|    └─Conv2d: 2-3                       (36,928)\n",
       "|    └─ReLU: 2-4                         --\n",
       "|    └─MaxPool2d: 2-5                    --\n",
       "|    └─Conv2d: 2-6                       (73,856)\n",
       "|    └─ReLU: 2-7                         --\n",
       "|    └─Conv2d: 2-8                       (147,584)\n",
       "|    └─ReLU: 2-9                         --\n",
       "|    └─MaxPool2d: 2-10                   --\n",
       "|    └─Conv2d: 2-11                      (295,168)\n",
       "|    └─ReLU: 2-12                        --\n",
       "|    └─Conv2d: 2-13                      (590,080)\n",
       "|    └─ReLU: 2-14                        --\n",
       "|    └─Conv2d: 2-15                      (590,080)\n",
       "|    └─ReLU: 2-16                        --\n",
       "|    └─MaxPool2d: 2-17                   --\n",
       "|    └─Conv2d: 2-18                      (1,180,160)\n",
       "|    └─ReLU: 2-19                        --\n",
       "|    └─Conv2d: 2-20                      (2,359,808)\n",
       "|    └─ReLU: 2-21                        --\n",
       "|    └─Conv2d: 2-22                      (2,359,808)\n",
       "|    └─ReLU: 2-23                        --\n",
       "|    └─MaxPool2d: 2-24                   --\n",
       "|    └─Conv2d: 2-25                      (2,359,808)\n",
       "|    └─ReLU: 2-26                        --\n",
       "|    └─Conv2d: 2-27                      (2,359,808)\n",
       "|    └─ReLU: 2-28                        --\n",
       "|    └─Conv2d: 2-29                      (2,359,808)\n",
       "|    └─ReLU: 2-30                        --\n",
       "|    └─MaxPool2d: 2-31                   --\n",
       "├─Sequential: 1-2                        --\n",
       "|    └─Conv2d: 2-32                      2,359,808\n",
       "|    └─MaxPool2d: 2-33                   --\n",
       "|    └─ReLU: 2-34                        --\n",
       "|    └─Flatten: 2-35                     --\n",
       "├─AgeGenderClassifier: 1-3               --\n",
       "|    └─Sequential: 2-36                  --\n",
       "|    |    └─Linear: 3-1                  1,049,088\n",
       "|    |    └─ReLU: 3-2                    --\n",
       "|    |    └─Dropout: 3-3                 --\n",
       "|    |    └─Linear: 3-4                  65,664\n",
       "|    |    └─ReLU: 3-5                    --\n",
       "|    |    └─Dropout: 3-6                 --\n",
       "|    |    └─Linear: 3-7                  8,256\n",
       "|    |    └─ReLU: 3-8                    --\n",
       "|    └─Sequential: 2-37                  --\n",
       "|    |    └─Linear: 3-9                  65\n",
       "|    |    └─Sigmoid: 3-10                --\n",
       "|    └─Sequential: 2-38                  --\n",
       "|    |    └─Linear: 3-11                 65\n",
       "|    |    └─Sigmoid: 3-12                --\n",
       "=================================================================\n",
       "Total params: 18,197,634\n",
       "Trainable params: 3,482,946\n",
       "Non-trainable params: 14,714,688\n",
       "================================================================="
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,224,224), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Define Training and validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(batch, model, loss_functions, optimzier):\n",
    "    model.train()\n",
    "    images, ages, genders = batch\n",
    "    predicted_genders, predicted_ages = model(images)\n",
    "    gender_loss_function, age_loss_function = loss_functions\n",
    "    gender_loss = gender_loss_function(predicted_genders.squeeze(),genders) \n",
    "    age_loss = age_loss_function(predicted_ages.squeeze(), ages)\n",
    "    total_loss = gender_loss + age_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "  \n",
    "    return total_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate_batch(data, model, loss_functions):\n",
    "    model.eval()\n",
    "    images, ages, genders = batch\n",
    "    predicted_gender, predicted_age = model(images)\n",
    "    gender_loss_function, age_loss_function = loss_functions\n",
    "    gender_loss = gender_loss_function(predicted_gender.squeeze(), genders)\n",
    "    age_loss = age_loss_function(predicted_age.squeeze(), ages)\n",
    "    total_loss = gender_loss + age_loss\n",
    "    \n",
    "    predicted_gender = (predicted_gender>0.5).squeeze()\n",
    "    gender_accuracy = (predicted_gender == genders).float().sum()\n",
    "    age_accuracy = torch.abs(ages - predicted_age).float().sum()\n",
    "    \n",
    "    return total_loss.item(), gender_accuracy, age_accuracy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Train Loss Value: 0.470\n",
      "epoch_age_acc:0.0551\n",
      "Test Loss Value: 0.470\n",
      "Gender Accuracy:68%\n",
      "Age Accuracy:0.00057\n",
      "Epoch: 2\n",
      "Train Loss Value: 0.458\n",
      "epoch_age_acc:0.0563\n",
      "Test Loss Value: 0.458\n",
      "Gender Accuracy:69%\n",
      "Age Accuracy:0.00059\n",
      "Epoch: 3\n",
      "Train Loss Value: 0.479\n",
      "epoch_age_acc:0.0580\n",
      "Test Loss Value: 0.479\n",
      "Gender Accuracy:70%\n",
      "Age Accuracy:0.00060\n",
      "Epoch: 4\n",
      "Train Loss Value: 0.462\n",
      "epoch_age_acc:0.0469\n",
      "Test Loss Value: 0.462\n",
      "Gender Accuracy:71%\n",
      "Age Accuracy:0.00049\n",
      "Epoch: 5\n",
      "Train Loss Value: 0.455\n",
      "epoch_age_acc:0.0404\n",
      "Test Loss Value: 0.455\n",
      "Gender Accuracy:69%\n",
      "Age Accuracy:0.00042\n",
      "Epoch: 6\n",
      "Train Loss Value: 0.447\n",
      "epoch_age_acc:0.0196\n",
      "Test Loss Value: 0.447\n",
      "Gender Accuracy:68%\n",
      "Age Accuracy:0.00020\n",
      "Epoch: 7\n",
      "Train Loss Value: 0.444\n",
      "epoch_age_acc:0.0101\n",
      "Test Loss Value: 0.444\n",
      "Gender Accuracy:70%\n",
      "Age Accuracy:0.00011\n",
      "Epoch: 8\n",
      "Train Loss Value: 0.440\n",
      "epoch_age_acc:0.0080\n",
      "Test Loss Value: 0.440\n",
      "Gender Accuracy:70%\n",
      "Age Accuracy:0.00008\n",
      "Epoch: 9\n",
      "Train Loss Value: 0.446\n",
      "epoch_age_acc:0.0062\n",
      "Test Loss Value: 0.446\n",
      "Gender Accuracy:70%\n",
      "Age Accuracy:0.00006\n",
      "Epoch: 10\n",
      "Train Loss Value: 0.452\n",
      "epoch_age_acc:0.0054\n",
      "Test Loss Value: 0.452\n",
      "Gender Accuracy:68%\n",
      "Age Accuracy:0.00006\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "validation_losses = []\n",
    "gender_accurcies = []\n",
    "age_accuracies = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch: {epoch+1}\")\n",
    "    epoch_train_losses =0\n",
    "    epoch_valid_losses = 0\n",
    "    epoch_valid_gender_acc =0\n",
    "    epoch_valid_age_acc = 0\n",
    "    ctr = 0\n",
    "    for batch in iter(train_dataset_loader):\n",
    "        batch_train_loss = train_batch(batch , model, loss_functions, optimizer)\n",
    "        epoch_train_losses += batch_train_loss\n",
    "    \n",
    "    epoch_train_losses /= len(train_dataset_loader)\n",
    "    train_losses.append(epoch_train_losses)\n",
    "    print(f\"Train Loss Value: {epoch_train_losses:0.3f}\")\n",
    "    \n",
    "    for batch in iter(validation_dataset_loader):\n",
    "        batch_valid_loss, batch_gender_acc, batch_age_acc = validate_batch(batch, model, loss_functions)\n",
    "        epoch_valid_losses += batch_valid_loss\n",
    "        epoch_valid_gender_acc += batch_gender_acc\n",
    "        epoch_valid_age_acc += batch_age_acc\n",
    "        ctr += len(batch[0])\n",
    "    print(f\"epoch_age_acc:{epoch_valid_age_acc:0.4f}\")\n",
    "    \n",
    "    \n",
    "    epoch_valid_losses /= len(validation_dataset_loader)\n",
    "    validation_losses.append(epoch_valid_losses)\n",
    "    print(f\"Test Loss Value: {epoch_train_losses:0.3f}\")\n",
    "    epoch_valid_gender_acc /=ctr\n",
    "    gender_accurcies.append(epoch_valid_gender_acc)\n",
    "    print(f\"Gender Accuracy:{epoch_valid_gender_acc*100:0.0f}%\")\n",
    "    epoch_valid_age_acc /= ctr\n",
    "    age_accuracies.append(epoch_valid_age_acc)\n",
    "    print(f\"Age Accuracy:{epoch_valid_age_acc:0.5f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
